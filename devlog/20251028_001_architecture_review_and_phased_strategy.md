# Architecture Review and Phased Development Strategy

**Date:** 2025-10-28
**Session:** Project architecture review and strategic planning
**Status:** Planning - Strategic direction established

---

## Executive Summary

Comprehensive review of PaleoBERT's architecture, identifying BERT's inherent limitations for document-level reasoning, and establishing a pragmatic phased development strategy prioritizing NER over RE, with document-level extensions as future work.

**Key Decision:** Focus on NER as core deliverable (high ROI), treat RE as best-effort bonus (caption-level only), defer document-level reasoning to Phase 3+.

---

## 1. System Input/Output Analysis

### 1.1 Input Format

**JSONL format with dual text representation:**

```json
{
  "raw_text": "Asaphiscus wheeleri was found in the Wheeler Formation at the House Range locality. This taxon occurs in Cambrian Stage 10 strata.",
  "norm_text": "Asaphiscus wheeleri was found in the Wheeler Formation at the House_Range locality. This taxon occurs in Cambrian_Stage_10 strata.",
  "align_map": {"0": 0, "1": 1, "...": "..."},
  "pub_id": "paper_12345",
  "cap_id": "fig3_caption"
}
```

**Input sources:**
- Open-access paleontology papers (captions, methods, stratigraphy sections)
- Geological bulletins/reports
- Museum specimen notes (where permitted)

### 1.2 Output Format

**Structured JSON with entities, relations, and provenance:**

```json
{
  "pub_id": "paper_12345",
  "cap_id": "fig3_caption",
  "raw_text": "...",

  "entities": [
    {
      "id": "e1",
      "type": "TAXON",
      "surface_form": "Asaphiscus wheeleri",
      "canonical_id": "TAXON:Asaphiscus_wheeleri",
      "char_start": 0,
      "char_end": 19,
      "confidence": 0.97
    },
    {
      "id": "e2",
      "type": "STRAT",
      "surface_form": "Wheeler Formation",
      "canonical_id": "STRAT:Wheeler_Fm",
      "char_start": 33,
      "char_end": 50,
      "confidence": 0.95
    }
  ],

  "relations": [
    {
      "subject": "e1",
      "predicate": "occurs_in",
      "object": "e2",
      "confidence": 0.89,
      "evidence_span": [0, 80],
      "evidence_type": "explicit"
    }
  ],

  "provenance": {
    "model_version": "paleo-pipeline-v1",
    "ner_model": "paleo-ner-v1",
    "re_model": "paleo-re-v1",
    "extracted_at": "2025-10-28T12:00:00Z"
  }
}
```

### 1.3 Target Information

**Entities (4 types):**
- **TAXON**: Organisms (Asaphiscus, Olenellus, Trilobita)
- **STRAT**: Stratigraphic units (Wheeler Formation, Burgess Shale)
- **CHRONO**: Chronostratigraphic units (Cambrian Stage 10, Paibian, Series 2)
- **LOC**: Localities (House Range, Utah, Antarctica)

**Relations (4 types):**
- **occurs_in**: TAXON â†’ STRAT (taxon found in formation)
- **found_at**: TAXON â†’ LOC (taxon found at locality)
- **part_of**: STRAT â†’ STRAT (stratigraphic hierarchy)
- **assigned_to**: STRAT â†’ CHRONO (formation assigned to time period)

---

## 2. Tokenizer Architecture Deep Dive

### 2.1 Role of Domain Vocabulary

**Critical clarification:** Domain vocabulary files (taxa.txt, strat_units.txt, etc.) are NOT for weight initialization or training data. They are for **tokenizer vocabulary expansion**.

**Process:**

```python
# Step 1: Add tokens to tokenizer vocabulary
tokenizer.add_tokens(["Asaphiscus", "Paibian", "Wheeler_Formation", ...])
# Returns: number of tokens added (~500)

# Step 2: Resize model embedding layer
model.resize_token_embeddings(len(tokenizer))
# Creates new embedding vectors (initialized randomly)

# Step 3: DAPT learns embeddings for new tokens
# 100M tokens of paleontology text â†’ new token embeddings learn meaning
```

### 2.2 Tokenization Behavior

**With domain vocabulary (PaleoBERT):**
```
"Olenellus" â†’ ["Olenellus"]  (1 token) âœ…
"Jiangshanian" â†’ ["Jiangshanian"]  (1 token) âœ…
"Cambrian_Stage_10" â†’ ["Cambrian_Stage_10"]  (1 token) âœ…
```

**Without domain vocabulary (base DeBERTa):**
```
"Olenellus" â†’ ["O", "##len", "##ell", "##us"]  (4 tokens) âŒ
"Jiangshanian" â†’ ["Ji", "##ang", "##shan", "##ian"]  (4 tokens) âŒ
```

**Novel terms (not in vocabulary):**
```
"Newtaxoniscus" â†’ ["New", "##tax", "##on", "##is", "##cus"]  (5 subwords) âœ…
# Still processable! No [UNK] token
# Subword components carry semantic information
```

### 2.3 Benefits of Domain Vocabulary

1. **Efficiency:** 75% reduction in sequence length for domain terms
2. **Semantic preservation:** "Cambrian" as single token vs fragmented ["Cam", "##brian"]
3. **Fragmentation rate reduction:** 95% â†’ 0% for added terms

**Fragmentation rate metric:**
```python
def fragmentation_rate(tokenizer, terms):
    fragmented = 0
    for term in terms:
        tokens = tokenizer.encode(term, add_special_tokens=False)
        if len(tokens) > 1:
            fragmented += 1
    return fragmented / len(terms) * 100

# Expected: 95% before â†’ 0% after for domain terms
```

---

## 3. NER Capability for Novel Terms

### 3.1 Core Principle: Context-based Recognition

**Key insight:** Deep learning NER learns **contextual patterns**, not word memorization.

**Training examples:**
```
"Olenellus wheeleri occurs in the Marjum Formation"
  [TAXON]  [TAXON]              [STRAT] [STRAT]

"Asaphiscus bonnensis found in Wheeler Shale"
  [TAXON]   [TAXON]               [STRAT] [STRAT]
```

**Model learns:**
- âŒ NOT: "Olenellus" = TAXON (memorization)
- âœ… YES: "X occurs in Y" pattern â†’ X=TAXON, Y=STRAT
- âœ… YES: Latin binomial pattern (2 capitalized words)
- âœ… YES: Morphological patterns ("-iscus", "-idae", "-morpha" â†’ TAXON)
- âœ… YES: Positional/syntactic cues

### 3.2 Inference on Novel Terms

**Example: Never-seen taxon**
```python
Input: "Newtaxoniscus mysteriosus occurs in the Wheeler Formation"

# Inference process:
# 1. Detect "occurs in" pattern
# 2. Position before "occurs in" â†’ likely TAXON
# 3. Two capitalized words â†’ Latin binomial pattern
# 4. Subword "##is", "##cus" seen in training (Asaphiscus, etc.)
# 5. "Wheeler Formation" in vocabulary â†’ STRAT confirmed

Output:
"Newtaxoniscus mysteriosus occurs in the Wheeler Formation"
  [TAXON]       [TAXON]               [STRAT] [STRAT]
  conf=0.87     conf=0.87             conf=0.95
```

### 3.3 Performance Expectations

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Term Type           â”‚  Precision â”‚   Recall   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ In vocabulary               â”‚   ~95%     â”‚   ~92%     â”‚
â”‚ (Olenellus, Wheeler_Fm)     â”‚            â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Novel but similar pattern   â”‚   ~85%     â”‚   ~78%     â”‚
â”‚ (Newtaxoniscus - binomial)  â”‚            â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Completely atypical         â”‚   ~65%     â”‚   ~55%     â”‚
â”‚ (Specimen ABC-123)          â”‚            â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Subword advantage:**
```
"Newtaxoniscus" â†’ ["New", "##tax", "##on", "##is", "##cus"]
                      |       |       |       |       |
                    new   taxonomy organism form  Latin suffix

# Shared suffixes with training data:
"Asaphiscus" â†’ ["Asaph", "##is", "##cus"]  â† overlapping subwords!
â†’ Similar embeddings â†’ similar predictions
```

---

## 4. BERT Architecture Limitations

### 4.1 Fixed Context Window Constraint

**Fundamental limitation:**
```
max_seq_length = 512 tokens (or 384 for NER/RE)
                 ^^^
                 Cannot process longer contexts

# Typical paper structure:
Title:        20 tokens
Abstract:     200 tokens
Introduction: 500 tokens  â† already exceeds 512!
Methods:      1000 tokens
Results:      2000 tokens
Total:        5000+ tokens

â†’ BERT cannot see entire document at once
```

### 4.2 Self-Attention Complexity

```
Sequence length 2Ã— â†’ Computation 4Ã— (O(nÂ²))

512 tokens:  512Â² = 262,144 operations
2048 tokens: 2048Â² = 4,194,304 operations (16Ã— more!)

â†’ VRAM explosion
â†’ Long document processing infeasible
```

### 4.3 Implications for Relation Extraction

**Current PaleoBERT design (OVERVIEW.md Â§ 4.1):**
> "Build candidate pairs from NER outputs **within sentence/caption windows**"

**Critical constraint:** RE only works for entities in the **same sentence/caption**.

**Problematic scenario:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Title: Trilobites of the Marjum Formation  â”‚  â† "Marjum Formation" (STRAT)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Section 3.2: Systematic Paleontology        â”‚
â”‚                                             â”‚
â”‚ Olenellus wheeleri Clark, 1924              â”‚  â† "Olenellus wheeleri" (TAXON)
â”‚                                             â”‚
â”‚ Description: Cephalon semi-circular with    â”‚  â† No mention of Formation!
â”‚ prominent genal spines...                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# NER results:
Sentence 1: [("Marjum Formation", "STRAT")]
Sentence 2: [("Olenellus wheeleri", "TAXON")]

# RE results:
No relation extracted âŒ
# Entities not in same window â†’ RE model never sees them together
```

### 4.4 Success Cases: Figure Captions

**Why captions work well:**
```
âœ… "Figure 3. Olenellus wheeleri from the Marjum Formation,
              House Range, Utah. Cambrian Stage 10."

# All entities in ONE caption:
NER: [TAXON, STRAT, LOC, CHRONO]
RE: All relations extractable!
  - (Olenellus wheeleri, occurs_in, Marjum Formation)
  - (Olenellus wheeleri, found_at, House Range)
  - (Marjum Formation, located_at, Utah)
  - (Marjum Formation, assigned_to, Cambrian Stage 10)
```

---

## 5. Document-level Reasoning Requirements

### 5.1 The Gap

**Current architecture:**
```
BERT (sentence/caption level)
  â†“
âœ… Explicit relations (same window)
âŒ Implicit relations (cross-sentence)
âŒ Document-level metadata inference
```

**What's missing:**
1. Primary formation/locality/age identification from document metadata
2. Implicit relation inference (entity in Results + formation in Title)
3. Cross-document knowledge integration

### 5.2 Proposed Extension Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PaleoBERT Core (Current Scope)          â”‚
â”‚                                                 â”‚
â”‚  Raw Text â†’ NER â†’ RE (sentence/caption level)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Document-level Module (Future Work)        â”‚
â”‚                                                 â”‚
â”‚  1. Metadata Extractor                         â”‚
â”‚     â€¢ Primary formation (from title/abstract)   â”‚
â”‚     â€¢ Primary locality (from title/abstract)    â”‚
â”‚     â€¢ Primary age (from stratigraphy section)   â”‚
â”‚                                                 â”‚
â”‚  2. Implicit Relation Inference                â”‚
â”‚     â€¢ Entity + Metadata â†’ likely relations      â”‚
â”‚     â€¢ Confidence scoring (0.4 ~ 0.7 range)     â”‚
â”‚                                                 â”‚
â”‚  3. Knowledge Graph Integration                â”‚
â”‚     â€¢ Cross-document co-occurrence patterns     â”‚
â”‚     â€¢ Taxon-formation associations from corpus  â”‚
â”‚     â€¢ Confidence boosting from multiple sources â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Unified Output                     â”‚
â”‚                                                 â”‚
â”‚  Explicit relations (high confidence, 0.8-0.95) â”‚
â”‚  + Implicit relations (medium conf, 0.4-0.7)    â”‚
â”‚  + Provenance tracking (explicit vs inferred)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.3 Evidence Layering Example

```json
{
  "triple": ["Olenellus wheeleri", "occurs_in", "Marjum Formation"],
  "evidence": [
    {
      "type": "explicit",
      "confidence": 0.92,
      "source": "sentence_47",
      "text": "...occurs in the Marjum Formation..."
    },
    {
      "type": "document_metadata",
      "confidence": 0.58,
      "source": "paper_title",
      "text": "Trilobites of the Marjum Formation"
    },
    {
      "type": "knowledge_graph",
      "confidence": 0.85,
      "source": "cross_document_stats",
      "text": "Co-occurred in 47/50 papers"
    }
  ]
}
```

**User filtering options:**
- High precision: `evidence_type == "explicit" AND confidence > 0.80`
- High recall: `confidence > 0.50` (include all evidence types)

---

## 6. Phased Development Strategy

### 6.1 Revised Milestone Plan

**Original plan (OVERVIEW.md):**
```
M1: DAPT complete
M2: NER baseline (F1 â‰¥ 0.80~0.90)
M3: RE baseline (F1 â‰¥ 0.75)
M4: End-to-end pipeline
M5: Release
```

**Revised pragmatic plan:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1: NER-Centric (CORE VALUE)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ M1: DAPT âœ…                                     â”‚
â”‚     Goal: MLM perplexity improvement            â”‚
â”‚     Timeline: 20-30 hours training              â”‚
â”‚                                                 â”‚
â”‚ M2: NER âœ…âœ…âœ… (PRIMARY DELIVERABLE)             â”‚
â”‚     Goal: F1 â‰¥ 0.85 (realistic target)          â”‚
â”‚     Validation: 4 entity types Ã— F1 â‰¥ 0.80      â”‚
â”‚     Deliverable: NER-only API/tool              â”‚
â”‚     Value: Sufficient for deployment!           â”‚
â”‚     Timeline: 2-3 weeks (data + training + eval)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 2: RE Experiment (BEST EFFORT)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ M3: Caption-level RE âš ï¸                        â”‚
â”‚     Goal: F1 â‰¥ 0.60 (lowered expectation)       â”‚
â”‚     Scope: Figure/table captions ONLY           â”‚
â”‚     Success criteria:                           â”‚
â”‚       - occurs_in F1 â‰¥ 0.70 (critical relation) â”‚
â”‚       - Precision â‰¥ 0.65 (avoid false positives)â”‚
â”‚     Failure condition: <0.60 after 3 epochs     â”‚
â”‚       â†’ Abort and move to Phase 3               â”‚
â”‚     Timeline: 1-2 weeks experiment              â”‚
â”‚                                                 â”‚
â”‚ M4: Basic Pipeline Release âœ…                   â”‚
â”‚     Components: NER (guaranteed) + RE (bonus)   â”‚
â”‚     Version: v1.0 (production-ready)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 3: Document-level (FUTURE RESEARCH)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ M5.1: Metadata Extraction                       â”‚
â”‚     Component: Document-level primary entity ID â”‚
â”‚     Timeline: 1-2 months (separate project)     â”‚
â”‚                                                 â”‚
â”‚ M5.2: Implicit Relation Inference               â”‚
â”‚     Component: Entity + metadata â†’ relations    â”‚
â”‚     Timeline: 2-3 months (research phase)       â”‚
â”‚                                                 â”‚
â”‚ M5.3: Knowledge Graph Integration               â”‚
â”‚     Component: Cross-document reasoning         â”‚
â”‚     Timeline: 3-6 months (separate publication?)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 Priority Justification

**Why NER first:**

| Capability | NER Only | NER + RE (caption) | NER + Doc-level |
|------------|----------|-------------------|----------------|
| Taxa extraction | âœ… | âœ… | âœ… |
| Formation extraction | âœ… | âœ… | âœ… |
| Locality extraction | âœ… | âœ… | âœ… |
| Age extraction | âœ… | âœ… | âœ… |
| **Direct relations** | âŒ | âœ… (50-70%) | âœ… (70-80%) |
| **Implicit relations** | âŒ | âŒ | âœ… (40-60%) |
| **Search indexing** | âœ… | âœ… | âœ… |
| **Auto-tagging** | âœ… | âœ… | âœ… |
| **Database population** | âœ… | âœ… | âœ… |

**Value proposition:**
- NER alone delivers 70% of use cases
- RE adds 20% (but 4Ã— effort)
- Doc-level adds 10% (but 10Ã— effort)

### 6.3 RE Success Rate by Context

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Context       â”‚ RE F1    â”‚  Reason             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Figure captions â”‚ 70-80%   â”‚ Dense, explicit     â”‚
â”‚ Table captions  â”‚ 65-75%   â”‚ Structured format   â”‚
â”‚ Abstracts       â”‚ 50-60%   â”‚ Long, implicit      â”‚
â”‚ Methods         â”‚ 30-40%   â”‚ Descriptive, vague  â”‚
â”‚ Results         â”‚ 40-50%   â”‚ Cross-references    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Strategic focus:** Target high-success contexts first (captions), defer low-success contexts to Phase 3.

### 6.4 ROI Analysis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Phase     â”‚ Effort   â”‚ Success  â”‚  ROI        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ NER         â”‚  â˜…â˜…â˜†â˜†â˜†  â”‚  85-90%  â”‚  â˜…â˜…â˜…â˜…â˜…     â”‚
â”‚ (Core)      â”‚  Medium  â”‚  High    â”‚  Excellent  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RE          â”‚  â˜…â˜…â˜…â˜…â˜†  â”‚  50-70%  â”‚  â˜…â˜…â˜…â˜†â˜†     â”‚
â”‚ (Caption)   â”‚  High    â”‚  Medium  â”‚  Moderate   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Doc-level   â”‚  â˜…â˜…â˜…â˜…â˜…  â”‚  40-60%  â”‚  â˜…â˜…â˜†â˜†â˜†     â”‚
â”‚ Metadata    â”‚  V.High  â”‚  Medium  â”‚  Low        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Knowledge   â”‚  â˜…â˜…â˜…â˜…â˜…  â”‚  30-50%  â”‚  â˜…â˜†â˜†â˜†â˜†     â”‚
â”‚ Graph       â”‚  V.High  â”‚  Low     â”‚  Very Low   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. Practical Implementation Guidelines

### 7.1 NER Phase (M2) - Maximize Quality

**Data requirements:**
- 5,000-20,000 labeled sentences
- Stratified split by publication (avoid leakage)
- Active learning for difficult cases

**Quality checklist:**
- [ ] Entity type coverage balanced (TAXON/STRAT/CHRONO/LOC)
- [ ] Diverse publication sources (journals, bulletins, notes)
- [ ] Edge cases included (abbreviations, novel taxa, informal names)
- [ ] Raw text span validation (not just normalized text)

**Success metrics:**
```python
NER_SUCCESS_CRITERIA = {
    "TAXON_f1": 0.90,   # Most important
    "STRAT_f1": 0.80,
    "CHRONO_f1": 0.80,
    "LOC_f1": 0.80,
    "overall_f1": 0.85,
}
```

### 7.2 RE Phase (M3) - Pragmatic Scoping

**Scope limitation:**
```python
RE_SCOPE = {
    "contexts": ["figure_captions", "table_captions"],
    "max_distance": 384,  # tokens between entities
    "min_confidence": 0.60,
}
```

**Abort criteria:**
```python
# Decision point: after 3 training epochs
if re_f1 < 0.60 or precision < 0.65:
    log("RE performance below threshold")
    log("Recommendation: Proceed to Phase 3 (doc-level)")
    decision = "ABORT_RE_TRAINING"
```

**Hard negative mining:**
```python
# Essential for RE training
# Example: TAXON and STRAT in same caption but no relation
"Figure 3. Olenellus wheeleri specimen. Scale bar: 5mm.
 From the Wheeler Formation collection."

â†’ ("Olenellus wheeleri", "Wheeler Formation") in same caption
â†’ But relation is INDIRECT (collection context, not occurrence)
â†’ Label: NONE (hard negative)
```

### 7.3 Document-level Phase (M5) - Research Mode

**Metadata extraction approach:**
```python
def extract_document_metadata(paper):
    """
    Extract primary entities from high-weight sections
    """
    # Weight by section
    weights = {
        "title": 3.0,
        "abstract": 2.0,
        "introduction": 1.0,
        "body": 0.5,
    }

    # Aggregate entity mentions
    entity_scores = defaultdict(float)
    for section, weight in weights.items():
        entities = ner_model(paper.sections[section])
        for entity in entities:
            entity_scores[entity] += weight

    # Select primary entities
    return {
        "primary_formation": top_entity(entity_scores, type="STRAT"),
        "primary_locality": top_entity(entity_scores, type="LOC"),
        "primary_age": top_entity(entity_scores, type="CHRONO"),
    }
```

---

## 8. Key Decisions and Rationale

### Decision 1: NER as Minimum Viable Product
**Rationale:** NER alone provides 70% of user value with 20% of effort. Ensures deliverable even if RE fails.

### Decision 2: Lower RE expectations
**Rationale:** BERT's context window limitation makes document-level RE infeasible. Caption-level RE at F1=0.60 is realistic and still useful.

### Decision 3: Defer document-level to Phase 3
**Rationale:** Requires architectural additions beyond BERT (metadata extraction, inference layer, KG integration). Separate research project scope.

### Decision 4: Caption-centric strategy
**Rationale:** Captions naturally contain dense entity co-occurrences. Highest ROI for RE component.

### Decision 5: Explicit failure criteria for RE
**Rationale:** Avoid endless tuning. Clear abort conditions enable pivot to Phase 3 if needed.

---

## 9. Risk Assessment

### High-confidence deliverables
- âœ… Tokenizer with domain vocabulary (P01)
- âœ… DAPT checkpoint (M1)
- âœ… NER model at F1 â‰¥ 0.85 (M2)

### Medium-confidence deliverables
- âš ï¸ RE model at F1 â‰¥ 0.60 (M3) - 60% success probability
- âš ï¸ Caption-level pipeline (M4) - depends on M3

### Low-confidence extensions
- ğŸ”® Document metadata extraction (M5.1) - research phase
- ğŸ”® Implicit relation inference (M5.2) - untested approach
- ğŸ”® Knowledge graph integration (M5.3) - long-term project

---

## 10. Next Steps

### Immediate (This week)
1. Complete P01 tokenizer setup (in progress)
   - Create domain vocabulary files (taxa.txt, etc.)
   - Build tokenizer_v1
   - Validation script

### Short-term (Next 2-4 weeks)
2. Data collection for DAPT (M1)
3. Data annotation for NER (M2)
4. Implement core modules (normalization, data loading, models)

### Medium-term (2-3 months)
5. DAPT training (20-30 hours)
6. NER training and evaluation
7. RE experiment (best effort)
8. Pipeline integration and release

### Long-term (6+ months)
9. Document-level extension (if M3 fails or post-v1.0)
10. Knowledge graph integration (research project)

---

## References

- OVERVIEW.md Â§ 4: Relation Extraction design
- OVERVIEW.md Â§ 5: Integration & Inference pipeline
- devlog/20251027_P01_tokenizer_setup.md: Tokenizer implementation plan

---

## Revision History

- 2025-10-28: Initial version - Architecture review and strategy established
